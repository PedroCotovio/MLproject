{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 (Supervised Learning) - Predicting Adoption and Adoption Speed\n",
    "\n",
    "In this task you should target 3 classification tasks:\n",
    "1. **Predicting  Adoption (binary classification task)**: create a new target from AdoptionSpeed that is 1 if AdoptionSpeed <> 4 and 0 otherwise.\n",
    "2. **Predicting AdoptionSpeed (multiclass classification)**: in this task you should you the original target AdoptionSpeed, whose values are in the set {0, 1, 2, 3 , 4} (5 classes). This is a very difficult problem. You might also want to consider 3 classes (for instance {0-1, 2-3, 4}, or other sets that make sense). \n",
    "3. **Train specialized models for cats and dogs**: train with cat/dog instances and check whether the classification performance changes when Predicting Adoption and Predicting AdoptionSpeed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**You should:**\n",
    "\n",
    "* Choose **one classifier in each category**: Tree models, Rule models, Linear models, Distance-based models, and Probabilistic models.\n",
    "* Use cross-validation to evaluate the results. \n",
    "* Present and discuss the results for different evaluation measures, present confusion matrices. Remember that not only overall results are important. Check what happens when learning to predict each class.\n",
    "* Describe the parameters used for each classifier and how their choice impacted or not the results.\n",
    "* Choose the best classifier and fundament you choice.\n",
    "* **Discuss critically your choices and the results!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We have only categorical data, but most of it is binary so we need to find the best models, classifing this type of data. Although it's clear that since we transformed our data in mostly binary features, we will have a much better performance with the binary target, then with the multiclass classification problem.\n",
    "\n",
    "Models to try:\n",
    "\n",
    "* LogitRegression (Can be used in multiclass classification, combining multiple regression functions.)\n",
    "  > Coeficient selection `l1-penalized`, solver `SAGA`\n",
    "* SVM Quadratic Kernel\n",
    "  > HyperParameter Selection - randomized search\n",
    "* MLP\n",
    "* Random Forests\n",
    "  > HyperParameter Selection - randomized search\n",
    "* Decision Tree\n",
    "  > HyperParameter Selection - randomized search\n",
    "* K_means with Russell Rao distance metric\n",
    "* Naive Bayes\n",
    "\n",
    "Feature Selection:\n",
    "\n",
    "* RFE with with CV / metric - accuracy\n",
    "* LassoCV with CV / metric - AIC & BIC\n",
    "\n",
    "Model Selection:\n",
    "\n",
    "* Test Error vs Train Error\n",
    "* ROC for every fold in CV\n",
    "* Learning Curves\n",
    "* Precision & Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. MultiClass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 LogitRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 1.1.1.1 Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import l1_min_c\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn import linear_model\n",
    "\n",
    "#Create Classifier with l1_min penality\n",
    "\n",
    "cs = l1_min_c(Dx, y, loss='log') * np.logspace(0, 7, 16)\n",
    "\n",
    "logit = linear_model.LogisticRegression(penalty='l1', solver='saga',\n",
    "                                      tol=1e-6, max_iter=int(1e6),\n",
    "                                      warm_start=True, multi_class= 'multinomial')\n",
    "# warm_start allows the model the use already computed coeficcients \n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "k_folds = 2\n",
    "coefs_ = []\n",
    "best = 0\n",
    "cv=StratifiedKFold(k_folds)\n",
    "for i, c in enumerate(cs):\n",
    "    print (i, ' of ', len(cs))\n",
    "    logit.set_params(C=c)\n",
    "    rfecv_logit = RFECV(estimator=logit, step=1, cv=cv,\n",
    "            scoring='accuracy', n_jobs = k_folds)\n",
    "    rfecv_logit.fit(Dx, y)\n",
    "    coefs_.append(rfecv_logit.estimator_.coef_.ravel().copy())\n",
    "    if max(rfecv_logit.grid_scores_) > best:\n",
    "        Brfecv_logit = rfecv_logit\n",
    "        break\n",
    "print(len(cs),' of ', len(cs),' : Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 1.1.1.2 Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Plot Regularization path of L1 penalization\n",
    "coefs_ = np.array(coefs_)\n",
    "plt.figure(figsize=(18, 8));\n",
    "plt.plot(np.log10(cs[0]), coefs_, marker='o')\n",
    "ymin, ymax = plt.ylim()\n",
    "plt.xlabel('log(C)')\n",
    "plt.ylabel('Coefficients')\n",
    "#plt.title('Logistic Regression Path')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"Feature's Ranking \\n\")\n",
    "for ix, cols in enumerate(Dx.columns):\n",
    "  print(cols, ': ', Brfecv_logit.ranking_[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"Optimal number of features : %d\" % rfecv_logit.n_features_)\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure(figsize=(18, 8));\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(Brfecv_logit.grid_scores_) + 1), Brfecv_logit.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy import interp\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "#get used features\n",
    "c_del = []\n",
    "for ix, cols in enumerate(Dx.columns):\n",
    "    if Brfecv_logit.ranking_[ix] != 1:\n",
    "        c_del.append(cols)\n",
    "Logx = Dx.drop(c_del, axis=1)\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "#ROC analysis\n",
    "\n",
    "classifier = Brfecv_logit.estimator_\n",
    "fig, ax = plt.subplots()\n",
    "for i, (train, test) in enumerate(cv.split(Logx, y)):\n",
    "    viz = roc_curve(classifier, Logx.iloc[test], y[test],\n",
    "                         name='ROC fold {}'.format(i),\n",
    "                         alpha=0.3, lw=1, ax=ax)\n",
    "    interp_tpr = interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "\n",
    "#Plot ROC\n",
    "\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "        label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "        label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "        lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "       title=\"Receiver operating characteristic example\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Classification - Results and Discussion "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
